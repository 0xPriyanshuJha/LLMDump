# LLMDump

LLMDump is a collection of various Generative AI (GenAI) applications, ranging from small utility tools to larger, more complex projects. This repository serves as a hub for experimenting with different LLMs (Large Language Models) and AI-powered applications.

## Features

🚀 Multi-LLM Support – Switch between multiple AI models like OpenAI, Mistral, Cohere, Ollama, and Hugging Face.

🔧 Small & Large Projects – Includes various GenAI-based tools, from chatbots to advanced AI-driven applications.

🏗 Modular & Extensible – Easily add or integrate new models and functionalities.

📡 API-Based Communication – Supports REST API calls to interact with LLMs.

🎨 User-Friendly Interfaces – Streamlit and other UI frameworks for seamless interaction.

## Included Projects

Multi-LLM Chat – A Streamlit-based chat application that allows users to select their preferred LLM and interact with it.

AI Text Summarizer – A tool that leverages LLMs to generate concise summaries from long texts.

Code Assistant – AI-powered coding assistant supporting multiple programming languages.

Document Analysis – OCR and AI-driven insights extraction from documents.

and many more . . . .

## Installation & Setup

Clone the repository:
```bash
git clone https://github.com/0xpriyanshujha/llmdump.git
cd llmdump
```

## Install dependencies:

```bash
pip install -r requirements.txt
```

## Set up API keys in a .env file or Streamlit Secrets:
```bash
OPENAI_API_KEY=your_openai_key
MISTRAL_API_KEY=your_mistral_key
COHERE_API_KEY=your_cohere_key
HUGGINGFACE_API_KEY=your_huggingface_key
```

Run the application:
```bash
streamlit run app.py
```

## Usage
* Select a model from the available LLMs.

* Enter your prompt or query in the chat interface.

* Receive AI-generated responses in real-time.


### Contributing

* We welcome contributions! Feel free to submit issues or pull requests to improve LLMDump.


## License

This project is licensed under the MIT License.

Made with ❤️ by Priyanshu Jha

